<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://weenews.github.io</id>
    <title>WeeNews&apos;s blog</title>
    <updated>2020-10-20T01:49:27.426Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://weenews.github.io"/>
    <link rel="self" href="https://weenews.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://weenews.github.io/images/avatar.png</logo>
    <icon>https://weenews.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, WeeNews&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[Linux进程、线程及调度算法]]></title>
        <id>https://weenews.github.io/post/linux-jin-cheng-xian-cheng-ji-diao-du-suan-fa/</id>
        <link href="https://weenews.github.io/post/linux-jin-cheng-xian-cheng-ji-diao-du-suan-fa/">
        </link>
        <updated>2020-08-16T08:35:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="进程与线程">进程与线程</h1>
<p>进程是资源分配的最小单位，线程是调度的最小单位</p>
<h2 id="进程控制块pcb">进程控制块PCB</h2>
<p>每一个进程都有各自的PCB（在Linux下即为task_struct），<strong>其描述了进程的资源</strong></p>
<figure data-type="image" tabindex="1"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200809213716021.png" alt="image-20200809213716021" loading="lazy"></figure>
<blockquote>
<p>1.读Linux内核以及相关的资料的时候，时刻要清醒地认识到它说的是内核态还是用户态的东西。</p>
<p>2.一个用户态进程/线程在内核中都是用一个task_struct的实例描述的，这个有点类似设计模式里面的桥接模式(handle-body), 用户态看到的进程PID，线程TID都是handle, task_struct是body。</p>
<p>3.C语言书里面讲的堆、栈大部分都是用户态的概念，用户态的堆、栈对应用户进程虚拟地址空间里的一个区域，栈向下增长，堆用malloc分配，向上增长。</p>
<p>3.用户空间的堆栈，在task_struct-&gt;mm-&gt;vm_area里面描述，都是属于进程虚拟地址空间的一个区域。</p>
<p>5.而内核态的栈在tsak_struct-&gt;stack里面描述，其底部是thread_info对象，thread_info可以用来快速获取task_struct对象。整个stack区域一般只有一个内存页(可配置)，32位机器也就是4KB。</p>
<p>6.所以说，一个进程的内核栈，也是进程私有的，只是在task_struct-&gt;stack里面获取。</p>
<p>7.内核态没有进程堆的概念，用kmalloc()分配内存，实际上是Linux内核统一管理的，一般用slab分配器，也就是一个内存缓存池，管理所有可以kmalloc()分配的内存。所以从原理上看，在Linux内核态，kmalloc分配的所有的内存，都是可以被所有运行在Linux内核态的task访问到的。</p>
<p>内核在创建进程时，会同时创建task_struct和进程相应堆栈。每个进程都会有两个堆栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。当进程在用户空间运行时，CPU堆栈寄存器的内容是用户堆栈地址，使用用户栈。当进程在内核空间时，CPU堆栈寄存器的内容是内核栈地址空间，使用的是内核栈。</p>
<p>当进程因为中断或系统调用进入内核时，进程使用的堆栈也需要从用户栈到内核栈。进程陷入内核态后，先把用户堆栈的地址保存到内核堆栈中，然后设置CPU堆栈寄存器为内核栈的地址，这样就完成了用户栈到内核栈的转换。</p>
<p>当进程从内核态恢复到用户态时，把内核中保存的用户态堆栈的地址恢复到堆栈指针寄存器即可。这样就实现了内核栈到用户栈的转换。</p>
<p>注意：陷入内核栈时，如何知道内核栈的地址呢？<br>
进程由用户栈到内核栈转换时，进程的内核栈总是空的。每次从用户态陷入内核时，得到的内核栈都是空的，所以在进程陷入内核时，直接把内核栈顶地址给堆栈指针寄存器即可。（内核栈地址是固定的）</p>
<h4 id="内核栈的作用">内核栈的作用</h4>
<p>我个人的理解是：在陷入内核后，系统调用中也是存在函数调用和自动变量，这些都需要栈支持。用户空间的栈<strong>显然不安全</strong>，需要内核栈的支持。此外，内核栈同时用于保存一些系统调用前(用户态）的信息（如用户空间栈指针、系统调用参数）。</p>
</blockquote>
<h3 id="task_struct的管理">task_struct的管理</h3>
<p>形成链表、树、哈希（pid -&gt; task_struct）以在适应不同场景，用空间换时间。</p>
<h2 id="进程状态">进程状态</h2>
<figure data-type="image" tabindex="2"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200809231549854.png" alt="image-20200809231549854" loading="lazy"></figure>
<p><strong>内存泄漏</strong>：进程如果没有释放资源就挂了，那不叫内存泄漏，因为进程挂了，它的内存资源也会被自动回收，</p>
<p>内存泄漏是指进程活着，且随着时间它使用的内存越来越多（由于某种原因不断的分配空间而没有释放）</p>
<blockquote>
<p>诊断：持续观察进程的内存使用情况，如果越来越多则说明由内存泄漏</p>
</blockquote>
<p><strong>cpulimit 原理</strong>：不断的停止和恢复进程的执行</p>
<pre><code class="language-bash">cpulimit -l 10 -p 12296
</code></pre>
<h2 id="fork原理">fork原理</h2>
<p>创建一个新的进程，就是使用fork()系统调用，所以要关注fork</p>
<figure data-type="image" tabindex="3"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200809224618314.png" alt="image-20200809224618314" loading="lazy"></figure>
<h3 id="fork-vfork-pthread_create">fork、vfork、pthread_create</h3>
<img src="C:\Users\xwq\AppData\Roaming\Typora\typora-user-images\image-20200810211002993.png" alt="image-20200810211002993" style="zoom:100%;" />
<p>fork、vfork、pthread_create的底层都是使用了clone，只不过clone的资源不同（实现上是指task_struct中的各成员）</p>
<p><strong>程序的执行</strong>：加载时只是做了一个虚拟空间和可执行文件之间的映射，并没有实际分配物理内存，更没有从磁盘读取文件内容到内存。代码段，数据段，堆，栈等这时候都只是存在于虚拟空间。程序开始执行后，先访问虚拟空间的代码段，操作系统的内存管理单元（MMU）通过TLB和Page Table查找虚拟页面（Page）所对应的物理内存页框（Page Frame）时，发现还没有对应的物理页框，也就是发生了缺页中断（Page Fault），这时候操作系统才会分配物理内存，并将程序的可执行文件读入内存中，开始执行程序代码。堆栈中的内存也是在需要访问的时候，发生Page Fault，然后才分配物理内存。</p>
<blockquote>
<p>CLONE_PARENT  创建的子进程的父进程是调用者的父进程，新进程与创建它的进程成了“兄弟”而不是“父子”</p>
<p>CLONE_FS      子进程与父进程共享相同的文件系统，包括root、当前目录、umask</p>
<p>CLONE_FILES   子进程与父进程共享相同的文件描述符（file descriptor）表</p>
<p>CLONE_NEWNS  在新的namespace启动子进程，namespace描述了进程的文件hierarchy</p>
<p>CLONE_SIGHAND  子进程与父进程共享相同的信号处理（signal handler）表</p>
<p>CLONE_PTRACE  若父进程被trace，子进程也被trace</p>
<p>CLONE_VFORK   父进程被挂起，直至子进程释放虚拟内存资源</p>
<p>CLONE_VM      子进程与父进程运行于相同的内存空间</p>
<p>CLONE_PID     子进程在创建时PID与父进程一致</p>
<p>CLONE_THREAD  Linux 2.4中增加以支持POSIX线程标准，子进程与父进程共享相同的线程群</p>
</blockquote>
<h3 id="fork-vs-vfork">fork  vs  vfork</h3>
<p>在Linux中，两者的区别实际上已经很小了，fork()其实已经足够来替代vfork()了。vfork()相对于fork()是不需要拷贝page table entries，就是虚拟内存空间。fork()的写时拷贝指的是具体的内存数据被改时拷贝，而虚拟内存空间布局还是必须要拷贝的。而且vfork()也没有写时拷贝的负担，所以vfork()实际还是比fork()开销小。但是vfork()的子进程里不能访问/修改原来的数据，这是未定义行为。一般采用vfork()的子进程，都会紧接着执行execv启动一个全新的进程，该进程的进程空间与父进程完全独立不相干，所以不需要复制父进程资源空间。</p>
<h3 id="pid与tgid">PID与TGID</h3>
<figure data-type="image" tabindex="4"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810205349657.png" alt="image-20200810205349657" loading="lazy"></figure>
<p>Linux中，使用getpid()或者top命令得到的是TGID，它代表进程ID（父线程的pid），真正task_struct中的pid可以使用gettid()或top -H得到，可以看到每个线程的pid。使用top -H 只能看到子线程的pid，看不到父线程的pid。</p>
<figure data-type="image" tabindex="5"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810214324956.png" alt="image-20200810214324956" loading="lazy"></figure>
<h2 id="subreaper与托孤">subreaper与托孤</h2>
<p>PR_SET_CHILD_SUBREAPER是linux3.4加入的新特性。把它设置为非零值，当前进程就会变成subreaper，就会像1号进程那样收养孤儿进程了。</p>
<figure data-type="image" tabindex="6"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810211931943.png" alt="image-20200810211931943" loading="lazy"></figure>
<p>父进程挂掉，子进程变为孤儿进程，其会被subreaper收养，向上找，找subreaper，直到init</p>
<figure data-type="image" tabindex="7"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810212257382.png" alt="image-20200810212257382" loading="lazy"></figure>
<p><strong>使用pstree看到的中间的init就是subreaper</strong></p>
<h1 id="进程调度">进程调度</h1>
<p>吞吐 vs 响应</p>
<p>吞吐和响应之间的矛盾：</p>
<ul>
<li>响应：最小化某任务的响应时间，哪怕以牺牲其他的任务为代价</li>
<li>吞吐：全局视野，整个系统的workload被最大化处理</li>
</ul>
<p>IO消耗型 vs CPU消耗型</p>
<ul>
<li>IO消耗型：CPU利用率低，大部分时间在等待IO，它对CPU的消耗较少，更重要的是要及时响应，这样类型的任务可以给将它的时间片化小一些而提高它的调度频率</li>
<li>CPU消耗型：这样的任务需要较多的CPU资源，可以给其划分较大的时间片，而降低它的调度频率</li>
</ul>
<h2 id="o1-调度">O(1) 调度</h2>
<p>先看图：</p>
<figure data-type="image" tabindex="8"><img src="https://picb.zhimg.com/80/v2-729fb18fa3ac1e41beff0fcd817c92a6_720w.jpg" alt="img" loading="lazy"></figure>
<p>看到这里，估计有部分读者已经领会到其中的奥义。2.6 kernel 里有 140 种优先级，所以我们就用长度为 140 的 array 去记录优先级。每个优先级下面用一个 FIFO queue 管理这个优先级下的 process。新来的插到队尾，先进先出。在这种情况下，insert / deletion 都是 O(1)。</p>
<p>那么，我们怎么找到当前最高优先级下面的可执行的 process 呢？如果从 0 开始一直遍历下去，算法虽然不是 O(N)，但是是跟优先级多寡相关的 O(M)，也不能算作 O(1)。在 2.6 scheduler 里，聪明的先贤们采用 bitarray。它为每种优先级分配一个 bit，如果这个优先级队列下面有 process，那么就对相应的 bit 染色，置为 1，否则置为 0。这样，问题就简化成寻找一个 bitarray 里面最高位是 1 的 bit（left-most bit），这基本上是一条 CPU 指令的事（fls）。</p>
<p>好，大致的思路齐备，我们来捋一捋完整的步骤：</p>
<ol>
<li>在 active bitarray 里，寻找 left-most bit 的位置 x。</li>
<li>在 active priority array（APA）中，找到对应队列 APA[x]。</li>
<li>从 APA[x] 中 dequeue 一个 process，dequeue 后，如果 APA[x] 的 queue 为空，那么将 active bitarray 里第 x bit置为 0。</li>
<li>对于当前执行完的 process，重新计算其 priority，然后 enqueue 到 expired priority array（EPA）相应的队里 EPA[priority]。</li>
<li>如果 priority 在 expired bitarray 里对应的 bit 为 0，将其置 1。</li>
<li>如果 active bitarray 全为零，将 active bitarray 和 expired bitarray 交换一下。</li>
</ol>
<p>当然，这里面还有一些细节，比如如果是 process 被抢占，其时间片没用完，那么第 4 步，enqueue 回 active priority queue 中。不过这和算法本身没太大关系，我们略过不表。</p>
<p><strong>历史地位</strong></p>
<p>2.6 O(1) scheduler 目前已经被性能略输一筹，同时更加强调公平性的 CFS（Completely Fair Scheduler）取代，但其以独特的设计，简单的算法，影响很多系统。在其刚问世时，很多 linux 发行版就迫不及待将其移植回 2.4 kernel。而程序君整个职业生涯中接触过的一些调度器中，都能见到 bitarray + priority queue 的身影。</p>
<figure data-type="image" tabindex="9"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200813010717364.png" alt="image-20200813010717364" loading="lazy"></figure>
<h2 id="早期26实时进程调度">早期2.6实时进程调度</h2>
<ul>
<li>SCHED_FIFO：不同优先级按照优先级高的先跑到睡眠，低优先级的再跑；同等优先级先进先出</li>
<li>SCHED_RR：不同优先级按照优先级高的先跑到睡眠，低优先级的再跑；同等优先级轮转</li>
</ul>
<h2 id="早期26非实时进程普通进程的调度和动态优先级">早期2.6非实时进程（普通进程）的调度和动态优先级</h2>
<p>SCHED_NORMAL</p>
<ul>
<li>调度在不同进程间轮转</li>
<li>-20 ~ 19的nice值</li>
<li>根据睡眠情况，动态奖励与惩罚（睡眠会被奖励，提高得到cpu的概率，运行会被惩罚）<strong>这样IO消耗型就可以抢的过CPU消耗型了</strong></li>
</ul>
<p>优先级高的进程可以得到更长的时间片并且可以在醒来时抢占低优先级的进程，之后再和它们一起轮转</p>
<p>**rt限制：**实时进程都睡眠了，非实时的才可以跑，后来linux打了补丁，实时进程在一个周期内最多占用cpu的比例为95%（可设置）</p>
<figure data-type="image" tabindex="10"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810224805315.png" alt="image-20200810224805315" loading="lazy"></figure>
<h2 id="现有普通进程的调度cfs完全公平调度算法">现有普通进程的调度CFS（完全公平调度算法）</h2>
<figure data-type="image" tabindex="11"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810233315094.png" alt="image-20200810233315094" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810233333970.png" alt="image-20200810233333970" loading="lazy"></figure>
<pre><code>nice值或者说调度与cpu占用率没有绝对的关系：调度只是解决在大家都要使用cpu时，将执行机会给谁的问题；cpu占用率主要由进程所执行的任务决定
</code></pre>
<blockquote>
<p>工具chrt和renice：</p>
<p>设置SCHED_FIFO和50 RT 优先级：chrt -f -a -p 50  pid</p>
<p>设置nice：renice -n -5 -g pid             nice  -n   5   ./a.out</p>
</blockquote>
<h1 id="负载均衡">负载均衡</h1>
<figure data-type="image" tabindex="13"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811005816300.png" alt="image-20200811005816300" loading="lazy"></figure>
<p>设置进程在那个核上运行：</p>
<ul>
<li><strong>设置affinity</strong></li>
</ul>
<figure data-type="image" tabindex="14"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811000609363.png" alt="image-20200811000609363" loading="lazy"></figure>
<ul>
<li><strong>taskset</strong></li>
</ul>
<figure data-type="image" tabindex="15"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811000751953.png" alt="image-20200811000751953" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811005916918.png" alt="image-20200811005916918" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811010116599.png" alt="image-20200811010116599" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811005957531.png" alt="image-20200811005957531" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811010017183.png" alt="image-20200811010017183" loading="lazy"></figure>
<figure data-type="image" tabindex="20"><img src="C:%5CUsers%5Cxwq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200811010253163.png" alt="image-20200811010253163" loading="lazy"></figure>
<p>不可抢占的时机：中断、软中断、进程上下文的spin_lock，其他都可以抢占</p>
<p>PREEMPT_RT补丁：</p>
<ul>
<li>spin_lock迁移为可调度的mutex，同时报了raw_spinlock_t</li>
<li>实现优先级继承协议</li>
<li>中断线程化</li>
<li>软中断线程化</li>
</ul>
<p>这样，系统就几乎变得随处可以抢占，变为一个实时的操作系统</p>
<p>https://zhuanlan.zhihu.com/p/33461281</p>
<h1 id="内存管理">内存管理</h1>
<h2 id="地址">地址</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[linux内核协议栈之网络信息统计SNMP]]></title>
        <id>https://weenews.github.io/post/linux-nei-he-xie-yi-zhan-zhi-wang-luo-xin-xi-tong-ji-snmp/</id>
        <link href="https://weenews.github.io/post/linux-nei-he-xie-yi-zhan-zhi-wang-luo-xin-xi-tong-ji-snmp/">
        </link>
        <updated>2020-05-11T10:53:58.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#snmp%E7%AE%80%E4%BB%8B">SNMP简介</a></li>
<li><a href="#snmp%E4%BF%A1%E6%81%AF%E7%BB%9F%E8%AE%A1%E6%A1%86%E6%9E%B6%E5%92%8C%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90">SNMP信息统计框架和实现分析</a>
<ul>
<li><a href="#%E6%A1%86%E6%9E%B6">框架</a></li>
<li><a href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0">具体实现</a></li>
</ul>
</li>
</ul>
</p>
<h1 id="snmp简介">SNMP简介</h1>
<p>SNMP是英文&quot;Simple Network Management Protocol&quot;的缩写，中文意思是&quot;简单网络管理协议&quot;。SNMP是一种简单网络管理协议，它属于TCP/IP五层协议中的应用层协议，用于网络管理的协议。SNMP主要用于网络设备的管理。由于SNMP协议简单可靠 ，受到了众多厂商的欢迎，成为了目前最为广泛的网管协议。<br>
<strong>SNMP的工作方式</strong>：管理员需要向设备获取数据，所以SNMP提供了【读】操作；管理员需要向设备执行设置操作，所以SNMP提供了【写】操作；设备需要在重要状况改变的时候，向管理员通报事件的发生，所以SNMP提供了【Trap】操作。</p>
<p>在具体实现上，SNMP为管理员提供了一个网管平台(NMS)，又称为【管理站】，负责网管命令的发出、数据存储、及数据分析。【被】监管的设备上运行一个SNMP代理(Agent))，代理实现设备与管理站的SNMP通信。<br>
<img src="https://img-blog.csdnimg.cn/20200421094847672.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlbnFpYW5neGlu,size_16,color_FFFFFF,t_70" alt="SNMP的实现结构" loading="lazy"><br>
管理站与代理端通过MIB进行接口统一，MIB定义了设备中的被管理对象。管理站和代理都实现了相应的MIB对象，使得双方可以识别对方的数据，实现通信。管理站向代理申请MIB中定义的数据，代理识别后，将管理设备提供的相关状态或参数等数据（<font color=red><strong>这些数据由内核的相关实现提供，存储于/proc等位置，下图是/proc/net/snmp文件中的内容，记录了ipv4相关的统计信息</strong></font>）转换为MIB定义的格式，应答给管理站，完成一次管理操作。<br>
<img src="https://img-blog.csdnimg.cn/20200421095714443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlbnFpYW5neGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"><br>
<strong>内核网络协议</strong>对SNMP协议的支持主要体现在统计了相关的网络信息，并将这些信息通过proc系统或其他配置文件进行展示（本人项目只是简单涉及到这个协议，这是我对它的一个简单理解，如果有误欢迎指正、交流）。下面的内容就是介绍内核网络栈是如何提供这些统计信息的，它的实现框架是怎样的。</p>
<h1 id="snmp信息统计框架和实现分析">SNMP信息统计框架和实现分析</h1>
<h2 id="框架">框架</h2>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20200422093723284.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlbnFpYW5neGlu,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="具体实现">具体实现</h2>
<p><strong>相关结构体和函数的代码展示在下方的代码块中，请自行查看。</strong><br>
1、首先在net结构中定义了一个netns_mib类型的mib成员，该成员中通过宏的方式定义了存放各协议统计信息的成员（<em><strong>是指针类型，所以需要初始化分配内存</strong></em>），它们的类型被定义在&lt;include/net/snmp.h&gt;中，大多数为一个数组，数组中存放各个统计信息，至于数组中什么位置存放什么信息则由定义在&lt;include/uapi/linux/snmp.h&gt;中的枚举类型定义，这些枚举类型都以0开始，表示数组的下标(见下方代码块)。</p>
<pre><code class="language-c">struct net {
	atomic_t		passive;	/* To decided when the network
						 * namespace should be freed.
						 */
	atomic_t		count;		/* To decided when the network
						 *  namespace should be shut down.
						 */
	spinlock_t		rules_mod_lock;

	u32			hash_mix;
	atomic64_t		cookie_gen;

	struct list_head	list;		/* list of network namespaces */
	struct list_head	cleanup_list;	/* namespaces on death row */
	struct list_head	exit_list;	/* Use only net_mutex */

	struct user_namespace   *user_ns;	/* Owning user namespace */
	spinlock_t		nsid_lock;
	struct idr		netns_ids;

	struct ns_common	ns;

	struct proc_dir_entry 	*proc_net;
	struct proc_dir_entry 	*proc_net_stat;

#ifdef CONFIG_SYSCTL
	struct ctl_table_set	sysctls;
#endif

	struct sock 		*rtnl;			/* rtnetlink socket */
	struct sock		*genl_sock;

	struct list_head 	dev_base_head;
	struct hlist_head 	*dev_name_head;
	struct hlist_head	*dev_index_head;
	unsigned int		dev_base_seq;	/* protected by rtnl_mutex */
	int			ifindex;
	unsigned int		dev_unreg_count;

	/* core fib_rules */
	struct list_head	rules_ops;


	struct net_device       *loopback_dev;          /* The loopback */
	struct netns_core	core;
	struct netns_mib	mib;    /* here*/
	struct netns_packet	packet;
	struct netns_unix	unx;
	struct netns_ipv4	ipv4;
#if IS_ENABLED(CONFIG_IPV6)
	struct netns_ipv6	ipv6;
#endif
......后面的代码省略
</code></pre>
<pre><code class="language-c">struct netns_mib {
	DEFINE_SNMP_STAT(struct tcp_mib, tcp_statistics);
	DEFINE_SNMP_STAT(struct ipstats_mib, ip_statistics);
	DEFINE_SNMP_STAT(struct linux_mib, net_statistics);
	DEFINE_SNMP_STAT(struct udp_mib, udp_statistics);
	DEFINE_SNMP_STAT(struct udp_mib, udplite_statistics);
	DEFINE_SNMP_STAT(struct icmp_mib, icmp_statistics);
	DEFINE_SNMP_STAT_ATOMIC(struct icmpmsg_mib, icmpmsg_statistics);

#if IS_ENABLED(CONFIG_IPV6)
	struct proc_dir_entry *proc_net_devsnmp6;
	DEFINE_SNMP_STAT(struct udp_mib, udp_stats_in6);
	DEFINE_SNMP_STAT(struct udp_mib, udplite_stats_in6);
	DEFINE_SNMP_STAT(struct ipstats_mib, ipv6_statistics);
	DEFINE_SNMP_STAT(struct icmpv6_mib, icmpv6_statistics);
	DEFINE_SNMP_STAT_ATOMIC(struct icmpv6msg_mib, icmpv6msg_statistics);
#endif
#ifdef CONFIG_XFRM_STATISTICS
	DEFINE_SNMP_STAT(struct linux_xfrm_mib, xfrm_statistics);
#endif
};
</code></pre>
<pre><code class="language-c">struct ipstats_mib {
	/* mibs[] must be first field of struct ipstats_mib */
	u64		mibs[IPSTATS_MIB_MAX];
	struct u64_stats_sync syncp;
};

/* ICMP */
#define ICMP_MIB_MAX	__ICMP_MIB_MAX
struct icmp_mib {
	unsigned long	mibs[ICMP_MIB_MAX];
};
</code></pre>
<pre><code class="language-c">       ......
enum
{
	TCP_MIB_NUM = 0,
	TCP_MIB_RTOALGORITHM,			/* RtoAlgorithm */
	TCP_MIB_RTOMIN,				/* RtoMin */
	TCP_MIB_RTOMAX,				/* RtoMax */
	TCP_MIB_MAXCONN,			/* MaxConn */
	TCP_MIB_ACTIVEOPENS,			/* ActiveOpens */
	TCP_MIB_PASSIVEOPENS,			/* PassiveOpens */
	TCP_MIB_ATTEMPTFAILS,			/* AttemptFails */
	TCP_MIB_ESTABRESETS,			/* EstabResets */
	TCP_MIB_CURRESTAB,			/* CurrEstab */
	TCP_MIB_INSEGS,				/* InSegs */
	TCP_MIB_OUTSEGS,			/* OutSegs */
	TCP_MIB_RETRANSSEGS,			/* RetransSegs */
	TCP_MIB_INERRS,				/* InErrs */
	TCP_MIB_OUTRSTS,			/* OutRsts */
	TCP_MIB_CSUMERRORS,			/* InCsumErrors */
	__TCP_MIB_MAX
};

/* udp mib definitions */
/*
 * RFC 1213:  MIB-II UDP group
 * RFC 2013 (updates 1213):  SNMPv2-MIB-UDP
 */
enum
{
	UDP_MIB_NUM = 0,
	UDP_MIB_INDATAGRAMS,			/* InDatagrams */
	UDP_MIB_NOPORTS,			/* NoPorts */
	UDP_MIB_INERRORS,			/* InErrors */
	UDP_MIB_OUTDATAGRAMS,			/* OutDatagrams */
	UDP_MIB_RCVBUFERRORS,			/* RcvbufErrors */
	UDP_MIB_SNDBUFERRORS,			/* SndbufErrors */
	UDP_MIB_CSUMERRORS,			/* InCsumErrors */
	UDP_MIB_IGNOREDMULTI,			/* IgnoredMulti */
	__UDP_MIB_MAX
};
            ......
</code></pre>
<p>2、协议族在初始化时为这些统计结构分配空间，进行初始化，这里初始化用的是per_cpu变量，即在每个cpu中都分配一个该变量的副本，这样做的目的是为了减少同步机制带来的性能损耗（在多处理器环境下避免了在修改此值时的加锁操作，通过空间换时间）。<a href="http://www.wowotech.net/linux_kenrel/per-cpu.html">per_cpu相关</a>。</p>
<pre><code class="language-c">static __net_init int ipv4_mib_init_net(struct net *net)
{
	int i;

	net-&gt;mib.tcp_statistics = alloc_percpu(struct tcp_mib);
	if (!net-&gt;mib.tcp_statistics)
		goto err_tcp_mib;
	net-&gt;mib.ip_statistics = alloc_percpu(struct ipstats_mib);
	if (!net-&gt;mib.ip_statistics)
		goto err_ip_mib;

	for_each_possible_cpu(i) {
		struct ipstats_mib *af_inet_stats;
		af_inet_stats = per_cpu_ptr(net-&gt;mib.ip_statistics, i);
		u64_stats_init(&amp;af_inet_stats-&gt;syncp);
	}

	net-&gt;mib.net_statistics = alloc_percpu(struct linux_mib);
	if (!net-&gt;mib.net_statistics)
		goto err_net_mib;
	net-&gt;mib.udp_statistics = alloc_percpu(struct udp_mib);
	if (!net-&gt;mib.udp_statistics)
		goto err_udp_mib;
	net-&gt;mib.udplite_statistics = alloc_percpu(struct udp_mib);
	if (!net-&gt;mib.udplite_statistics)
		goto err_udplite_mib;
	net-&gt;mib.icmp_statistics = alloc_percpu(struct icmp_mib);
	if (!net-&gt;mib.icmp_statistics)
		goto err_icmp_mib;
	net-&gt;mib.icmpmsg_statistics = kzalloc(sizeof(struct icmpmsg_mib),
					      GFP_KERNEL);
	if (!net-&gt;mib.icmpmsg_statistics)
		goto err_icmpmsg_mib;

	tcp_mib_init(net);
	return 0;

err_icmpmsg_mib:
	free_percpu(net-&gt;mib.icmp_statistics);
err_icmp_mib:
	free_percpu(net-&gt;mib.udplite_statistics);
err_udplite_mib:
	free_percpu(net-&gt;mib.udp_statistics);
err_udp_mib:
	free_percpu(net-&gt;mib.net_statistics);
err_net_mib:
	free_percpu(net-&gt;mib.ip_statistics);
err_ip_mib:
	free_percpu(net-&gt;mib.tcp_statistics);
err_tcp_mib:
	return -ENOMEM;
}

static __net_exit void ipv4_mib_exit_net(struct net *net)
{
	kfree(net-&gt;mib.icmpmsg_statistics);
	free_percpu(net-&gt;mib.icmp_statistics);
	free_percpu(net-&gt;mib.udplite_statistics);
	free_percpu(net-&gt;mib.udp_statistics);
	free_percpu(net-&gt;mib.net_statistics);
	free_percpu(net-&gt;mib.ip_statistics);
	free_percpu(net-&gt;mib.tcp_statistics);
}

static __net_initdata struct pernet_operations ipv4_mib_ops = {
	.init = ipv4_mib_init_net,
	.exit = ipv4_mib_exit_net,
};

static int __init init_ipv4_mibs(void)
{
	return register_pernet_subsys(&amp;ipv4_mib_ops);
}
</code></pre>
<p>3、內镶在网络栈中的统计函数在对应的位置进行统计，将信息写入上述的统计字段（统计到当前cpu的副本中）。比如下方udp_recvmsg函数中的<strong>UDP_INC_STATS_USER(sock_net(sk), UDP_MIB_CSUMERRORS, is_udplite)</strong> 和<br>
<strong>UDP_INC_STATS_USER(sock_net(sk), UDP_MIB_INERRORS, is_udplite)</strong> 就是在统计校验和错误的数据包以及接收出错的数据包<br>
这些宏其实就是增加对应统计字段的值。</p>
<pre><code class="language-c">int udp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int noblock,
		int flags, int *addr_len)
{
	struct inet_sock *inet = inet_sk(sk);
	DECLARE_SOCKADDR(struct sockaddr_in *, sin, msg-&gt;msg_name);
	struct sk_buff *skb;
	unsigned int ulen, copied;
	int peeked, off = 0;
	int err;
	int is_udplite = IS_UDPLITE(sk);
	bool checksum_valid = false;
	bool slow;

	if (flags &amp; MSG_ERRQUEUE)
		return ip_recv_error(sk, msg, len, addr_len);

try_again:
	skb = __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),
				  &amp;peeked, &amp;off, &amp;err);
	if (!skb)
		goto out;

	ulen = skb-&gt;len - sizeof(struct udphdr);
	copied = len;
	if (copied &gt; ulen)
		copied = ulen;
	else if (copied &lt; ulen)
		msg-&gt;msg_flags |= MSG_TRUNC;

	/*
	 * If checksum is needed at all, try to do it while copying the
	 * data.  If the data is truncated, or if we only want a partial
	 * coverage checksum (UDP-Lite), do it before the copy.
	 */

	if (copied &lt; ulen || UDP_SKB_CB(skb)-&gt;partial_cov) {
		checksum_valid = !udp_lib_checksum_complete(skb);
		if (!checksum_valid)
			goto csum_copy_err;
	}

	if (checksum_valid || skb_csum_unnecessary(skb))
		err = skb_copy_datagram_msg(skb, sizeof(struct udphdr),
					    msg, copied);
	else {
		err = skb_copy_and_csum_datagram_msg(skb, sizeof(struct udphdr),
						     msg);

		if (err == -EINVAL)
			goto csum_copy_err;
	}

	if (unlikely(err)) {
		trace_kfree_skb(skb, udp_recvmsg);
		if (!peeked) {
			atomic_inc(&amp;sk-&gt;sk_drops);
			UDP_INC_STATS_USER(sock_net(sk),
					   UDP_MIB_INERRORS, is_udplite);
		}
		goto out_free;
	}

	if (!peeked)
		UDP_INC_STATS_USER(sock_net(sk),
				UDP_MIB_INDATAGRAMS, is_udplite);

	sock_recv_ts_and_drops(msg, sk, skb);

	/* Copy the address. */
	if (sin) {
		sin-&gt;sin_family = AF_INET;
		sin-&gt;sin_port = udp_hdr(skb)-&gt;source;
		sin-&gt;sin_addr.s_addr = ip_hdr(skb)-&gt;saddr;
		memset(sin-&gt;sin_zero, 0, sizeof(sin-&gt;sin_zero));
		*addr_len = sizeof(*sin);
	}
	if (inet-&gt;cmsg_flags)
		ip_cmsg_recv_offset(msg, skb, sizeof(struct udphdr), off);

	err = copied;
	if (flags &amp; MSG_TRUNC)
		err = ulen;

out_free:
	skb_free_datagram_locked(sk, skb);
out:
	return err;

csum_copy_err:
	slow = lock_sock_fast(sk);
	if (!skb_kill_datagram(sk, skb, flags)) {
		UDP_INC_STATS_USER(sock_net(sk), UDP_MIB_CSUMERRORS, is_udplite);
		UDP_INC_STATS_USER(sock_net(sk), UDP_MIB_INERRORS, is_udplite);
	}
	unlock_sock_fast(sk, slow);

	/* starting over for a new packet, but check if we need to yield */
	cond_resched();
	msg-&gt;msg_flags &amp;= ~MSG_TRUNC;
	goto try_again;
}
</code></pre>
<p>4、将这些数据通过proc系统（虚拟文件系统，存在于内存中）向用户提供访问。这时需要将对应字段在所有cpu中的副本加起来，这个工作在ipv4中是通过以下函数完成的。</p>
<pre><code class="language-c">unsigned long snmp_fold_field(void __percpu *mib, int offt)
{
	unsigned long res = 0;
	int i;

	for_each_possible_cpu(i)
		res += snmp_get_cpu_field(mib, i, offt);
	return res;
}
</code></pre>
<p>所有统计信息都被通过/proc/net/snmp文件展示给用户。<br>
这部分的实现在对应协议族下的proc.c文件中，将上述统计信息按照特定格式展示在proc文件中。</p>
<pre><code class="language-c">static int snmp_seq_show(struct seq_file *seq, void *v)
{
	int i;
	struct net *net = seq-&gt;private;

	seq_puts(seq, &quot;Ip: Forwarding DefaultTTL&quot;);

	for (i = 0; snmp4_ipstats_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %s&quot;, snmp4_ipstats_list[i].name);

	seq_printf(seq, &quot;\nIp: %d %d&quot;,
		   IPV4_DEVCONF_ALL(net, FORWARDING) ? 1 : 2,
		   sysctl_ip_default_ttl);

	BUILD_BUG_ON(offsetof(struct ipstats_mib, mibs) != 0);
	for (i = 0; snmp4_ipstats_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %llu&quot;,
			   snmp_fold_field64(net-&gt;mib.ip_statistics,
					     snmp4_ipstats_list[i].entry,
					     offsetof(struct ipstats_mib, syncp)));

	icmp_put(seq);	/* RFC 2011 compatibility */
	icmpmsg_put(seq);

	seq_puts(seq, &quot;\nTcp:&quot;);
	for (i = 0; snmp4_tcp_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %s&quot;, snmp4_tcp_list[i].name);

	seq_puts(seq, &quot;\nTcp:&quot;);
	for (i = 0; snmp4_tcp_list[i].name != NULL; i++) {
		/* MaxConn field is signed, RFC 2012 */
		if (snmp4_tcp_list[i].entry == TCP_MIB_MAXCONN)
			seq_printf(seq, &quot; %ld&quot;,
				   snmp_fold_field(net-&gt;mib.tcp_statistics,
						   snmp4_tcp_list[i].entry));
		else
			seq_printf(seq, &quot; %lu&quot;,
				   snmp_fold_field(net-&gt;mib.tcp_statistics,
						   snmp4_tcp_list[i].entry));
	}

	seq_puts(seq, &quot;\nUdp:&quot;);
	for (i = 0; snmp4_udp_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %s&quot;, snmp4_udp_list[i].name);

	seq_puts(seq, &quot;\nUdp:&quot;);
	for (i = 0; snmp4_udp_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %lu&quot;,
			   snmp_fold_field(net-&gt;mib.udp_statistics,
					   snmp4_udp_list[i].entry));

	/* the UDP and UDP-Lite MIBs are the same */
	seq_puts(seq, &quot;\nUdpLite:&quot;);
	for (i = 0; snmp4_udp_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %s&quot;, snmp4_udp_list[i].name);

	seq_puts(seq, &quot;\nUdpLite:&quot;);
	for (i = 0; snmp4_udp_list[i].name != NULL; i++)
		seq_printf(seq, &quot; %lu&quot;,
			   snmp_fold_field(net-&gt;mib.udplite_statistics,
					   snmp4_udp_list[i].entry));

	seq_putc(seq, '\n');
	return 0;
}

static __net_init int ip_proc_init_net(struct net *net)
{
	if (!proc_create(&quot;sockstat&quot;, S_IRUGO, net-&gt;proc_net,
			 &amp;sockstat_seq_fops))
		goto out_sockstat;
	if (!proc_create(&quot;netstat&quot;, S_IRUGO, net-&gt;proc_net, &amp;netstat_seq_fops))
		goto out_netstat;
	if (!proc_create(&quot;snmp&quot;, S_IRUGO, net-&gt;proc_net, &amp;snmp_seq_fops))
		goto out_snmp;

	return 0;

out_snmp:
	remove_proc_entry(&quot;netstat&quot;, net-&gt;proc_net);
out_netstat:
	remove_proc_entry(&quot;sockstat&quot;, net-&gt;proc_net);
out_sockstat:
	return -ENOMEM;
}
</code></pre>
<p>本文只是简单对内核网络栈对snmp的支持进行了分析，总的来说，这部分内容还是比较独立的，在开发自己的协议栈时，如果要增加这部分内容，那么你所需要做的并不复杂，唯一比较麻烦的地方可能就在于在增加了自己定义的内容后需要重新编译内核，因为你改动了net结构体！这个结构体是所有内核网络协议栈共用的！<br>
OVER</p>
]]></content>
    </entry>
</feed>